/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as serializers from "../../..";
import { OpenAiApi } from "@fern-api/open-ai";
import * as core from "../../../../core";

export const CreateChatCompletionRequest: core.serialization.ObjectSchema<
    serializers.CreateChatCompletionRequest.Raw,
    OpenAiApi.CreateChatCompletionRequest
> = core.serialization.object({
    model: core.serialization.string(),
    messages: core.serialization.list(
        core.serialization.lazyObject(async () => (await import("../../..")).ChatCompletionRequestMessage)
    ),
    temperature: core.serialization.number().optional(),
    topP: core.serialization.property("top_p", core.serialization.number().optional()),
    n: core.serialization.number().optional(),
    stream: core.serialization.boolean().optional(),
    stop: core.serialization.list(core.serialization.string()).optional(),
    maxTokens: core.serialization.property("max_tokens", core.serialization.number().optional()),
    presencePenalty: core.serialization.property("presence_penalty", core.serialization.number().optional()),
    frequencyPenalty: core.serialization.property("frequency_penalty", core.serialization.number().optional()),
    logitBias: core.serialization.property(
        "logit_bias",
        core.serialization.record(core.serialization.string(), core.serialization.number().optional()).optional()
    ),
    user: core.serialization.string().optional(),
});

export declare namespace CreateChatCompletionRequest {
    interface Raw {
        model: string;
        messages: serializers.ChatCompletionRequestMessage.Raw[];
        temperature?: number | null;
        top_p?: number | null;
        n?: number | null;
        stream?: boolean | null;
        stop?: string[] | null;
        max_tokens?: number | null;
        presence_penalty?: number | null;
        frequency_penalty?: number | null;
        logit_bias?: Record<string, number | null | undefined> | null;
        user?: string | null;
    }
}
